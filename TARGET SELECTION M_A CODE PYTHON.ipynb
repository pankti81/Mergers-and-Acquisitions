{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"TARGET SELECTION M&A CODE PYTHON.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"pk57f9CTF5UH","executionInfo":{"status":"ok","timestamp":1630532890022,"user_tz":240,"elapsed":10,"user":{"displayName":"Pankti Parekh","photoUrl":"","userId":"14066177463290336561"}}},"source":["\"\"\"\n","it takes data (like a CSV or TSV file, or a SQL database) \n","it creates a Python object with rows and columns called data frame \n","that looks very similar to table in a statistical software.\n","\"\"\"\n"," \n","# Importing pandas module\n","import pandas as pd"],"execution_count":1,"outputs":[]},{"cell_type":"code","metadata":{"id":"MkVQs_2nHLT-","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1630532915848,"user_tz":240,"elapsed":25833,"user":{"displayName":"Pankti Parekh","photoUrl":"","userId":"14066177463290336561"}},"outputId":"3a349c82-8c63-436c-e8d7-e283dfdea5af"},"source":["\"\"\"\n","The CSV file consisting of financial data of merger and acquisition \n","is stored in google drive\n","Collaborate this google file with the code\n","by mounting it by using the following lines of code\n","\"\"\"\n","\n","from google.colab import drive\n","drive.mount('/content/gdrive')"],"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/gdrive\n"]}]},{"cell_type":"code","metadata":{"id":"ckWv2HbaHxz2","colab":{"base_uri":"https://localhost:8080/","height":404},"executionInfo":{"status":"error","timestamp":1630532916077,"user_tz":240,"elapsed":260,"user":{"displayName":"Pankti Parekh","photoUrl":"","userId":"14066177463290336561"}},"outputId":"2f3c31b8-5b96-4033-f809-2f4b3009fa0d"},"source":["\"\"\"\n","The CSV file location is now given\n","read_csv will read that file from mentioned location\n","pandas library will convert this excel file \n","into tabular format dataframe\n","\"\"\"\n","\n","# Making data frame \n","import pandas as pd \n","rock=pd.read_csv('gdrive/My Drive/book1.csv')"],"execution_count":3,"outputs":[{"output_type":"error","ename":"FileNotFoundError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-3-2acc7e021859>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;31m# Making data frame\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0mrock\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'gdrive/My Drive/book1.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[1;32m    686\u001b[0m     )\n\u001b[1;32m    687\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 688\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    689\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    690\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    452\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    453\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 454\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfp_or_buf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    455\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    456\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    946\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    947\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 948\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    949\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    950\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1178\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"c\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1179\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"c\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1180\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1181\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1182\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"python\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m   2008\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"usecols\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0musecols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2009\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2010\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2011\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2012\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[0;34m()\u001b[0m\n","\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._setup_parser_source\u001b[0;34m()\u001b[0m\n","\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'gdrive/My Drive/book1.csv'"]}]},{"cell_type":"code","metadata":{"id":"WHdaiHnQIigl","executionInfo":{"status":"aborted","timestamp":1630532916037,"user_tz":240,"elapsed":35,"user":{"displayName":"Pankti Parekh","photoUrl":"","userId":"14066177463290336561"}}},"source":["\"\"\"\n","top 5 rows of data frame are returned and stored in a new variable.\n","No parameter is passed to .head() method \n","since by default it is 5.\n","\"\"\"\n","\n","# Calling head() method  \n","rock.head()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"GDyIUEVOImyQ","executionInfo":{"status":"aborted","timestamp":1630532916043,"user_tz":240,"elapsed":40,"user":{"displayName":"Pankti Parekh","photoUrl":"","userId":"14066177463290336561"}}},"source":["# Import necessary libraries for visualisation\n","from pandas.plotting import scatter_matrix\n","from pandas.plotting import andrews_curves\n","\n","# Builtin colormaps, colormap handling utilities, and the ScalarMappable mixin.\n","from matplotlib import cm\n","import matplotlib.pyplot as plt\n","\n","\n","\"\"\"\n","Organizing the data and looking ⁸at it and forming input vectors\n","To get a better understanding of what the dataset contains \n","and how we can use the data to train our model\n","Each financial parameter plays role in determining the output \n","So each parameter is an input vector\n","\"\"\"\n","\n","# Organizing the data \n","feature_names = ['SG', 'PATG', 'ROCE', 'TA','DER']     \n","\"\"\"\n","SG= Sales growth\n","PATG= PAT Growth\n","ROCE= Return on Capital Employed\n","TA= Total assets\n","DER= Debt equity ratio\n","\"\"\"\n","\n","# Defining input and output vectors\n","X = rock[feature_names]\n","Y = rock['Output']\n","\n","\n","# Scatter matrix plot\n","scatter_matrix(X)\n","print('     SCATTER MATRIX PLOT')\n","\n","# Density plot\n","scatter_matrix(X, diagonal='kde')\n","plt.show()\n","\n","# Andrews curve\n","plt.figure()\n","andrews_curves(rock, 'Output', colormap='winter')\n","print('       ANDREWS CURVE')\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"PS1NZaLCIpQa","executionInfo":{"status":"aborted","timestamp":1630532916047,"user_tz":240,"elapsed":43,"user":{"displayName":"Pankti Parekh","photoUrl":"","userId":"14066177463290336561"}}},"source":["# Creating train & test samples\n","from sklearn.model_selection import train_test_split\n","X_train, X_test, y_train, y_test = train_test_split(X, Y, random_state=0)\n","\n","# This package provides several common utility functions and transformer classes \n","# It changes raw feature vectors into a representation that is suitable for estimators.\n","# Transforms features by scaling each feature to a given range which is (0,1) by default\n","from sklearn.preprocessing import MinMaxScaler\n","scaler = MinMaxScaler()\n","\n","# Fit to data, then transform it.\n","X_train = scaler.fit_transform(X_train)    \n","\n","# Scaling features of X_test according to feature_range (default=(0,1)).\n","X_test = scaler.transform(X_test)           "],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"AXRfydkmI1fC","executionInfo":{"status":"aborted","timestamp":1630532916049,"user_tz":240,"elapsed":44,"user":{"displayName":"Pankti Parekh","photoUrl":"","userId":"14066177463290336561"}}},"source":["# Logistic Regression\n","\n","# Import Library\n","from sklearn.linear_model import LogisticRegression\n","\n","# Create logistic regression object\n","logreg = LogisticRegression()\n","\n","# Train the model using the training sets and check score\n","logreg.fit(X_train, y_train)\n","\n","# Predict output\n","predicted=logreg.predict(X_test)\n","print(predicted)\n","\n","# Calculate accuracy of training and testing dataset\n","print('Accuracy of Logistic regression classifier on training set: {:.2f}'\n","     .format(logreg.score(X_train, y_train)))\n","print('Accuracy of Logistic regression classifier on test set: {:.2f}'\n","     .format(logreg.score(X_test, y_test)))\n","\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"wC5U6pLbI5tJ","executionInfo":{"status":"aborted","timestamp":1630532916051,"user_tz":240,"elapsed":44,"user":{"displayName":"Pankti Parekh","photoUrl":"","userId":"14066177463290336561"}}},"source":["#Decision Trees\n","\n","#Import package\n","from sklearn.tree import DecisionTreeClassifier\n","\n","#Create tree object\n","clf = DecisionTreeClassifier().fit(X_train, y_train)\n","\n","print('Accuracy of Decision Tree classifier on training set: {:.2f}'\n","     .format(clf.score(X_train, y_train)))\n","print('Accuracy of Decision Tree classifier on test set: {:.2f}'\n","     .format(clf.score(X_test, y_.test)))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Bq53ScLAI-op","executionInfo":{"status":"aborted","timestamp":1630532916053,"user_tz":240,"elapsed":43,"user":{"displayName":"Pankti Parekh","photoUrl":"","userId":"14066177463290336561"}}},"source":["#KNN\n","from sklearn.neighbors import KNeighborsClassifier\n","knn = KNeighborsClassifier()\n","knn.fit(X_train, y_train)\n","print('Accuracy of K-NN classifier on training set: {:.2f}'\n","     .format(knn.score(X_train, y_train)))\n","print('Accuracy of K-NN classifier on test set: {:.2f}'\n","     .format(knn.score(X_test, y_test)))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"G5ygqJVFJBjp","executionInfo":{"status":"aborted","timestamp":1630532916062,"user_tz":240,"elapsed":51,"user":{"displayName":"Pankti Parekh","photoUrl":"","userId":"14066177463290336561"}}},"source":["# Gaussian Naive Bayes\n","\n","from sklearn.naive_bayes import GaussianNB\n","gnb = GaussianNB()\n","gnb.fit(X_train, y_train)\n","print('Accuracy of GNB classifier on training set: {:.2f}'\n","     .format(gnb.score(X_train, y_train)))\n","print('Accuracy of GNB classifier on test set: {:.2f}'\n","     .format(gnb.score(X_test, y_test)))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"f3iMBBsCJEvN","executionInfo":{"status":"aborted","timestamp":1630532916066,"user_tz":240,"elapsed":54,"user":{"displayName":"Pankti Parekh","photoUrl":"","userId":"14066177463290336561"}}},"source":["#SVM\n","\n","#Import library\n","from sklearn.svm import SVC\n","\n","# Create SVM classification object \n","svm = SVC()\n","\n","#Fitting model created\n","svm.fit(X_train, y_train)\n","\n","print('Accuracy of SVM classifier on training set: {:.2f}'\n","     .format(svm.score(X_train, y_train)))\n","print('Accuracy of SVM classifier on test set: {:.2f}'\n","     .format(svm.score(X_test, y_test)))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"w_dVBANJUtZe"},"source":[""]},{"cell_type":"code","metadata":{"id":"NQpGOoLwJH88","executionInfo":{"status":"aborted","timestamp":1630532916074,"user_tz":240,"elapsed":62,"user":{"displayName":"Pankti Parekh","photoUrl":"","userId":"14066177463290336561"}}},"source":["THANKS!!!!"],"execution_count":null,"outputs":[]}]}